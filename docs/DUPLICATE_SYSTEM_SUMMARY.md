# Current Duplicate Detection System - Complete Overview

## üìã Summary

Your system has **4 different types of duplicate detection** working together, each serving a specific purpose. Here's the complete breakdown:

---

## üîç 1. Content Duplicates (SHA256 Hash)

### What It Detects
Files with **identical content** - exact byte-for-byte copies.

### How It Works
- Calculates SHA256 hash of file content
- Compares hashes to find exact matches
- Works on **repository files only** (`is_managed = 1`)

### Database Fields
- `content_hash` - Not stored (calculated on-demand)
- `duplicate_type` - Can be set to `'CONTENT_DUP'`
- `parent_file` - Points to the original/parent program_number

### Features Using This
1. **Delete Content Duplicates** ([gcode_database_manager.py:7760-8010](gcode_database_manager.py#L7760-L8010))
   - Scans repository files
   - Groups by SHA256 hash
   - Keeps parent/lowest number
   - Deletes duplicates to `deleted/` folder

2. **Re-scan Repository** ([gcode_database_manager.py:8221-8400](gcode_database_manager.py#L8221-L8400))
   - Re-calculates hashes for all repository files
   - Updates `validation_status` to `'REPEAT'` for duplicates
   - Marks parent files

### Scope
- ‚úÖ **Repository files only** - `WHERE is_managed = 1`
- ‚ùå **External files ignored** - Even if they have duplicate content

### Example
```
Repository:
  o12345   (hash: abc123) - PARENT, KEEP
  o12346   (hash: abc123) - DUPLICATE, DELETE
  o12347   (hash: xyz789) - UNIQUE, KEEP

External:
  o12345   (hash: abc123) - NOT TOUCHED (is_managed=0)
```

---

## üè∑Ô∏è 2. Name Duplicates (Program Number Collision)

### What It Detects
Files with **same program number but different content** (e.g., two files both named `o12345` but with different G-code).

### How It Works
- During folder scan, tracks program numbers seen
- If duplicate number found, renames with suffix
- Only affects files **in the current scan batch**

### Database Fields
- `duplicate_type` - Can be set to `'NAME_COLLISION'`
- `program_number` - Gets renamed with suffix like `o12345(1)`

### Features Using This
1. **Auto-Rename During Scan** ([gcode_database_manager.py:2616-2665](gcode_database_manager.py#L2616-L2665))
   - Happens automatically during `scan_folder()`
   - Tracks `seen_in_scan` dictionary
   - Renames on-the-fly: `o12345` ‚Üí `o12345(1)` ‚Üí `o12345(2)`

2. **Rename Name Duplicates** ([gcode_database_manager.py:8900-9100](gcode_database_manager.py#L8900-L9100))
   - Manual cleanup operation
   - Finds existing name collisions in database
   - Renames to next available number

### Scope
- ‚úÖ **Within current scan batch** - Only files being scanned now
- ‚úÖ **Both repository and external** - Prevents database conflicts
- ‚ùå **Does NOT rename existing database files**

### Example
```
Scanning folder with:
  File1: o12345.nc    (content: G00 X0 Y0)
  File2: o12345_v2.nc (program number: o12345, content: G01 X1 Y1)

Result:
  o12345   (from File1) - First occurrence, no change
  o12345(1) (from File2) - Renamed to avoid conflict
```

---

## üë• 3. Duplicate Groups (Related Variants)

### What It Detects
Families of related programs that are **intentionally similar** (e.g., different sizes of the same part).

### How It Works
- Manual grouping by user
- Links variants together with shared `duplicate_group` ID
- Maintains parent-child relationships

### Database Fields
- `duplicate_group` - UUID or group identifier linking related programs
- `parent_file` - Points to master/parent program
- `duplicate_type` - Can be `'SOLID'` or other type indicator

### Features Using This
Currently **not fully implemented** - Fields exist but no UI for managing groups yet.

**Planned Features:**
- Group similar programs together
- Navigate between variants
- See all versions of a part family

### Scope
- ‚úÖ **User-defined grouping**
- ‚úÖ **Cross-repository/external** (can group any programs)

### Example
```
Group: "6.25 OD Spacer Family" (duplicate_group: uuid-1234)
  o12345 (parent, CB: 54mm, type: SOLID)
  o12346 (variant, CB: 60mm, parent_file: o12345)
  o12347 (variant, CB: 70mm, parent_file: o12345)
```

---

## üîÑ 4. REPEAT Status (Validation-Based Detection)

### What It Detects
Files marked as duplicates by the **validation/scanning process** (combination of content + name detection).

### How It Works
- `validation_status` set to `'REPEAT'` during repository scans
- Indicates file is a duplicate that should be reviewed/cleaned
- Used as a flag for batch cleanup operations

### Database Fields
- `validation_status` - Set to `'REPEAT'` for duplicates
- `parent_file` - Points to parent if known

### Features Using This
1. **Re-scan Repository Duplicates** ([gcode_database_manager.py:8221-8400](gcode_database_manager.py#L8221-L8400))
   - Scans all repository files
   - Marks duplicates with `validation_status = 'REPEAT'`
   - Sets parent references

2. **Delete REPEAT Status Files** ([gcode_database_manager.py:8400-8600](gcode_database_manager.py#L8400-L8600))
   - Finds all files with `WHERE validation_status = 'REPEAT'`
   - Deletes them to `deleted/` folder
   - Keeps parent files

### Scope
- ‚úÖ **Repository files only**
- ‚ùå **External files not marked REPEAT**

### Example
```
After re-scan:
  o12345 - validation_status: PASS (parent)
  o12346 - validation_status: REPEAT (duplicate of o12345)
  o12347 - validation_status: REPEAT (duplicate of o12345)

After cleanup:
  o12345 - KEPT
  o12346 - DELETED
  o12347 - DELETED
```

---

## üìä Database Schema

### Programs Table - Duplicate Fields

```sql
CREATE TABLE programs (
    -- ... other fields ...

    -- Duplicate tracking
    duplicate_type TEXT,      -- 'SOLID', 'NAME_COLLISION', 'CONTENT_DUP', NULL
    parent_file TEXT,         -- Reference to parent program_number
    duplicate_group TEXT,     -- Group ID for related duplicates

    -- Validation
    validation_status TEXT,   -- 'PASS', 'REPEAT', 'CRITICAL', 'WARNING', etc.

    -- Repository vs External
    is_managed INTEGER        -- 1 = repository, 0 = external
)
```

---

## üéØ How They Work Together

### During Folder Scan

1. **Name Collision Detection** (Auto)
   - Tracks program numbers in `seen_in_scan` dictionary
   - Renames duplicates: `o12345` ‚Üí `o12345(1)`
   - Prevents database conflicts

2. **Content Hash** (Optional)
   - Can calculate SHA256 during import
   - Not stored, calculated on-demand

### During Repository Management

3. **Content Duplicate Scan**
   - Calculate SHA256 for all repository files
   - Group by hash
   - Mark duplicates for deletion

4. **REPEAT Status Marking**
   - Re-scan finds both content + name duplicates
   - Sets `validation_status = 'REPEAT'`
   - Batch cleanup of REPEAT files

### Manual Operations

5. **Duplicate Groups** (Future)
   - User defines part families
   - Links variants with `duplicate_group`
   - Maintains relationships

---

## üîß Available Operations

### From "Manage Duplicates" Dialog

**1. Delete Content Duplicates**
- **What:** Finds files with identical SHA256 hash
- **Scope:** Repository only (`is_managed = 1`)
- **Action:** Deletes duplicates, keeps parent/lowest number
- **Safety:** Preview before deletion, external files protected

**2. Rename Name Duplicates**
- **What:** Fixes program number collisions
- **Scope:** Repository or external
- **Action:** Renames to next available number (e.g., `o12345` ‚Üí `o12346`)
- **Safety:** Updates file content + database

**3. Scan for Duplicates (Report Only)**
- **What:** Read-only report of all duplicates
- **Scope:** Repository only
- **Action:** Shows what would be deleted/renamed
- **Safety:** No changes made

**4. Re-scan Repository**
- **What:** Re-calculate all hashes, mark REPEAT status
- **Scope:** Repository only
- **Action:** Updates `validation_status` field
- **Safety:** No deletions, just marking

**5. Clean REPEAT Status Files**
- **What:** Delete all files marked `validation_status = 'REPEAT'`
- **Scope:** Repository only
- **Action:** Batch deletion to `deleted/` folder
- **Safety:** Keeps parents, preview before deletion

---

## üîç Duplicate Detection Methods

### Method 1: SHA256 Content Hash
```python
import hashlib
sha256_hash = hashlib.sha256()
with open(filepath, 'rb') as f:
    for byte_block in iter(lambda: f.read(4096), b""):
        sha256_hash.update(byte_block)
file_hash = sha256_hash.hexdigest()
```
**Pros:** Exact match, byte-perfect accuracy
**Cons:** Slow for large files, doesn't catch "similar" files

### Method 2: Program Number Comparison
```python
# During scan
if record.program_number in seen_in_scan:
    suffix = 1
    while f"{original_prog_num}({suffix})" in seen_in_scan:
        suffix += 1
    record.program_number = f"{original_prog_num}({suffix})"
```
**Pros:** Fast, prevents database conflicts
**Cons:** Only catches name collisions, not content duplicates

### Method 3: Parent-Child Tracking
```python
# Mark duplicate
UPDATE programs SET
    duplicate_type = 'CONTENT_DUP',
    parent_file = 'o12345'  -- parent program number
WHERE program_number = 'o12346'
```
**Pros:** Maintains relationships, allows grouping
**Cons:** Requires manual setup or smart detection

---

## üí° What's Missing (From Feature Roadmap)

### Advanced Duplicate Detection (Not Implemented)

**From FEATURE_ROADMAP.md - Minor Enhancement #7:**

**Target Features:**
- **Similarity percentage** (90% similar, 95% similar)
  - Not exact match, but "close enough"
  - Fuzzy matching for near-duplicates

- **Ignore comment differences**
  - Same G-code, different comments
  - Same toolpath, different formatting

- **Side-by-side preview of similar files**
  - Visual comparison before deciding
  - Highlight differences

- **Merge similar programs**
  - Combine duplicate metadata
  - Keep best version

- **Auto-suggest parent program**
  - Smart detection of original vs copy
  - Suggest grouping

- **Machine learning similarity**
  - AI-based detection of similar toolpaths
  - Semantic similarity, not just byte match

**Priority:** ‚≠ê‚≠ê‚≠ê

---

## üéØ Current System Strengths

### ‚úÖ What Works Well

1. **Exact Content Matching**
   - SHA256 hash detection is 100% accurate
   - No false positives
   - Fast enough for repository scans

2. **Automatic Name Conflict Prevention**
   - Scan-time renaming prevents database conflicts
   - Works for both repository and external
   - Transparent to user

3. **Safe Deletion**
   - Always keeps parent/lowest number
   - Moves to `deleted/` folder, not permanent delete
   - Preview before action

4. **Repository Isolation**
   - External files never accidentally deleted
   - Clear separation with `is_managed` flag
   - Can reference same files without conflict

### ‚ö†Ô∏è What Needs Improvement

1. **No Similarity Detection**
   - Can't find "almost duplicate" files
   - Miss files with minor differences
   - No fuzzy matching

2. **Manual Group Management**
   - `duplicate_group` field exists but no UI
   - Can't easily group related variants
   - No visual family tree

3. **No Content-Aware Detection**
   - Doesn't ignore comments
   - Doesn't ignore whitespace/formatting
   - Can't detect same toolpath with different code

4. **No Smart Parent Detection**
   - Relies on program number or manual marking
   - Doesn't auto-detect which is original
   - Can't infer relationships

---

## üìà Recommendations

### Short Term (Easy Wins)

1. **Add Duplicate Group UI**
   - Use existing `duplicate_group` field
   - Allow manual grouping of variants
   - Show grouped programs together

2. **Improve REPEAT Status Workflow**
   - Better visualization of REPEAT files
   - One-click cleanup
   - Undo capability

3. **Add "Find Similar" Button**
   - Search for programs with similar dimensions
   - Tolerance-based matching (¬±0.1mm)
   - Quick way to find variants

### Medium Term (More Effort)

4. **Fuzzy Content Matching**
   - Strip comments before hash comparison
   - Normalize whitespace
   - Detect same toolpath with different formatting

5. **Similarity Percentage**
   - Calculate % difference between files
   - Show "95% similar" badge
   - Allow threshold-based grouping

6. **Part Family Tree UI**
   - Visual hierarchy of related programs
   - Drag-drop to reorganize
   - Expand/collapse families

### Long Term (Advanced Features)

7. **ML-Based Similarity**
   - Train model on G-code patterns
   - Semantic similarity detection
   - Auto-suggest relationships

8. **Smart Parent Detection**
   - Analyze timestamps, versions, usage
   - Auto-detect original vs copy
   - Suggest groupings

---

## üîß Technical Details

### Hash Calculation Performance

**Current Implementation:**
```python
# 4KB block reading for efficiency
sha256_hash = hashlib.sha256()
with open(filepath, 'rb') as f:
    for byte_block in iter(lambda: f.read(4096), b""):
        sha256_hash.update(byte_block)
```

**Performance:**
- Small files (<100KB): < 10ms
- Medium files (100KB-1MB): 50-200ms
- Large files (1MB+): 500ms-2s

**Optimization Ideas:**
- Cache hashes in database (add `content_hash` column)
- Skip recalculation if file unchanged (check mtime)
- Parallel processing for batch scans

### Database Queries

**Find Content Duplicates:**
```sql
-- Current approach (on-demand)
SELECT program_number, file_path
FROM programs
WHERE is_managed = 1
-- Then calculate hashes in Python

-- Better approach (if cached):
SELECT content_hash, COUNT(*) as count
FROM programs
WHERE is_managed = 1
GROUP BY content_hash
HAVING count > 1
```

**Find Name Duplicates:**
```sql
SELECT program_number, COUNT(*) as count
FROM programs
GROUP BY program_number
HAVING count > 1
```

**Find REPEAT Status:**
```sql
SELECT program_number, parent_file
FROM programs
WHERE validation_status = 'REPEAT'
  AND is_managed = 1
```

---

## üìö Related Documentation

- [DUPLICATE_HANDLING_EXPLAINED.md](DUPLICATE_HANDLING_EXPLAINED.md) - Repository vs External isolation
- [DELETE_CONTENT_DUPLICATES_FEATURE.md](DELETE_CONTENT_DUPLICATES_FEATURE.md) - Content duplicate deletion
- [FEATURE_ROADMAP.md](FEATURE_ROADMAP.md) - Advanced duplicate detection plans (lines 841-854)
- [REPOSITORY_IMPLEMENTATION_SUMMARY.md](REPOSITORY_IMPLEMENTATION_SUMMARY.md) - Repository management system

---

## üéâ Summary

### You Currently Have:

1. ‚úÖ **SHA256 Content Duplicate Detection** - Exact byte-match detection
2. ‚úÖ **Program Number Collision Prevention** - Auto-rename during scan
3. ‚úÖ **Parent-Child Relationships** - `parent_file` and `duplicate_type` fields
4. ‚úÖ **REPEAT Status Marking** - Validation-based duplicate flagging
5. ‚úÖ **Safe Deletion Workflow** - Preview, keep parents, move to deleted/
6. ‚úÖ **Repository Isolation** - External files protected from cleanup

### You Don't Have (Yet):

1. ‚ùå **Similarity Detection** - Find "almost duplicate" files
2. ‚ùå **Fuzzy Matching** - Ignore comments, whitespace, formatting
3. ‚ùå **Duplicate Group UI** - Manage part families visually
4. ‚ùå **Smart Parent Detection** - Auto-detect original vs copy
5. ‚ùå **ML-Based Detection** - Semantic similarity matching

### Overall Assessment:

Your duplicate detection system is **solid and production-ready** for:
- ‚úÖ Exact duplicate detection and cleanup
- ‚úÖ Name conflict prevention
- ‚úÖ Safe repository management

But could be **enhanced** with:
- üîÑ Similarity detection for near-duplicates
- üîÑ Better UI for managing duplicate groups
- üîÑ Smarter auto-grouping of variants

---

*Last Updated: 2025-11-26*
*Current Status: 4 detection methods implemented, advanced features planned*
